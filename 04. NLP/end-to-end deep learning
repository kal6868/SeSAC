from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout # Permute: 주어진 패턴에 따라서 입력 차수 변경 
from tensorflow.keras.layers import add, dot, concatenate
from tensorflow.keras.layers import LSTM

input_encoder_m= Sequential()
input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))
input_encoder_m.add(Dropout(0.3))

input_encoder_c = Sequential()
input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))
input_encoder_c.add(Dropout(0.3))

question_encoder = Sequential()
question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))
question_encoder.add(Dropout(0.3))

print(input_encoded_m.shape)
print(question_encoded.shape)
result = dot([input_encoded_m, question_encoded], axes=(2,2))
result.shape

match = dot([input_encoded_m, question_encoded], axes=(2,2))
match = Activation('softmax')(match)

response = add([match, input_encoded_c]) #  (samples, story_maxlen, question_maxlex)
response = Permute((2,1))(response) #  (samples, question_maxlen, story_maxlex)

anwser = concatenate([response, question_encoded])
anwser = LSTM(32)(anwser) # (sampels, 32)
anwser = Dropout(0.5)(anwser) 
anwser = Dense(vocab_size)(anwser) # (samples, vocab_size) # YES/NO
anwser = Activation('softmax')(anwser)
model = Model([input_sequence, question], anwser)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

